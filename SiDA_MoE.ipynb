{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zishan-Shao/Learning_LLM/blob/main/SiDA_MoE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWAG6iLlYVot"
      },
      "source": [
        "# SiDA-MoE\n",
        "This project is aimed to execute and evaluate the Sparsity inspired mixture of experts model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8-BY2vHTRzF",
        "outputId": "1056aa69-833e-4b5a-ff36-42c68e97bad0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ForEImRVT625",
        "outputId": "ff6a3879-38e3-4dc4-fee6-5006c786abef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n",
            "/content/drive/MyDrive/MLSys_Learning\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive\n",
        "!mkdir -p MLSys_Learning\n",
        "%cd MLSys_Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysCppkGFT_TT",
        "outputId": "9ad2e2bb-03f6-4310-c6ae-25522f242778"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/MLSys_Learning/SiDA-MoE\n"
          ]
        }
      ],
      "source": [
        "#!git clone https://github.com/timlee0212/SiDA-MoE.git\n",
        "%cd SiDA-MoE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sflID-JwUCCi"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "#!pip install -r requirements.txt\n",
        "!bash setup.sh\n",
        "print(\"All set !!!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b4_V7ifUeQy",
        "outputId": "1585fdf9-9928-4b7e-b573-e88c263dd6cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/MLSys_Learning/SiDA-MoE/src\n"
          ]
        }
      ],
      "source": [
        "%cd src"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "psUHjTDXVhO_"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install evaluate\n",
        "import evaluate\n",
        "print(evaluate.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ej69gJ9aVvaP",
        "outputId": "446e35ab-3934-4e30-b220-354a21ec7236"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gputil\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-py3-none-any.whl size=7392 sha256=d7ed89989e3a038950b37ee31425a359289bde600af3037eb8eef24e558d9c05\n",
            "  Stored in directory: /root/.cache/pip/wheels/a9/8a/bd/81082387151853ab8b6b3ef33426e98f5cbfebc3c397a9d4d0\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install gputil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4adMXsHgWrLv",
        "outputId": "2814829c-d182-44a3-f8c4-bf12dc27eba9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Dec 29 16:06:14 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA L4                      Off | 00000000:00:03.0 Off |                    0 |\n",
            "| N/A   49C    P8              16W /  72W |      1MiB / 23034MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# check if nividia-smi is installed:\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Suppress INFO and WARNING logs"
      ],
      "metadata": {
        "id": "D5DHFAtJx8As"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtx0SsNtUpup",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5099faef-b9e7-4ffe-cc8f-1683214d18da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-12-29 16:06:21.342381: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-29 16:06:21.362533: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-29 16:06:21.368662: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "Directory /content/drive/MyDrive/MLSys_Learning/SiDA-MoE/data/sst2/switch-base-8/ already exists\n",
            "README.md: 100% 35.3k/35.3k [00:00<00:00, 5.44MB/s]\n",
            "======================================================================================\n",
            "1.149023 GB\n",
            "[0]: 0.026374 GB\n",
            "[1]: 0.149443 GB\n",
            "[2]: 0.026373 GB\n",
            "[3]: 0.149443 GB\n",
            "[4]: 0.026373 GB\n",
            "[5]: 0.149443 GB\n",
            "[6]: 0.026373 GB\n",
            "[7]: 0.149443 GB\n",
            "[8]: 0.026373 GB\n",
            "[9]: 0.149443 GB\n",
            "[10]: 0.026373 GB\n",
            "[11]: 0.149443 GB\n",
            "[Experts]  0.8966560363769531\n",
            "13it [00:13,  1.07s/it]\n",
            "Average GPU Utilization over time during inference: 80.74%\n"
          ]
        }
      ],
      "source": [
        "!python3 main.py --model=switch-base-8"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "RBfuVf22DZdf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rU0d2pfGXt8m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90c0b5c8-44d4-4379-8c06-e5ebe07304fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-12-29 15:39:07.460398: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-29 15:39:07.487248: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-29 15:39:07.496416: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "Directory /content/drive/MyDrive/MLSys_Learning/SiDA-MoE/data/rte/switch-base-8/ already exists\n",
            "======================================================================================\n",
            "1.149023 GB\n",
            "[0]: 0.026374 GB\n",
            "[1]: 0.149443 GB\n",
            "[2]: 0.026373 GB\n",
            "[3]: 0.149443 GB\n",
            "[4]: 0.026373 GB\n",
            "[5]: 0.149443 GB\n",
            "[6]: 0.026373 GB\n",
            "[7]: 0.149443 GB\n",
            "[8]: 0.026373 GB\n",
            "[9]: 0.149443 GB\n",
            "[10]: 0.026373 GB\n",
            "[11]: 0.149443 GB\n",
            "[Experts]  0.8966560363769531\n",
            "4it [00:08,  2.07s/it]\n",
            "Average GPU Utilization over time during inference: 85.85%\n"
          ]
        }
      ],
      "source": [
        "!python3 main.py --dataset=rte --model=switch-base-8\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nW46pt_mX75j"
      },
      "source": [
        "It is really nice to see that our code works for the switch-base-16, so we may now run the rest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1TqUjoVW6Te",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "343b523e-2e17-4990-9cf0-316b3ccc6ed8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-12-29 15:39:49.953798: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-29 15:39:49.973162: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-29 15:39:49.978886: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "Directory /content/drive/MyDrive/MLSys_Learning/SiDA-MoE/data/sst2/switch-base-16/ already exists\n",
            "======================================================================================\n",
            "1.992910 GB\n",
            "[0]: 0.026374 GB\n",
            "[1]: 0.290091 GB\n",
            "[2]: 0.026373 GB\n",
            "[3]: 0.290091 GB\n",
            "[4]: 0.026373 GB\n",
            "[5]: 0.290091 GB\n",
            "[6]: 0.026373 GB\n",
            "[7]: 0.290091 GB\n",
            "[8]: 0.026373 GB\n",
            "[9]: 0.290091 GB\n",
            "[10]: 0.026373 GB\n",
            "[11]: 0.290091 GB\n",
            "[Experts]  1.7405433654785156\n",
            "13it [00:25,  1.94s/it]\n",
            "Average GPU Utilization over time during inference: 91.34%\n"
          ]
        }
      ],
      "source": [
        "!python3 main.py --model=switch-base-16\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUWfItmQZtn-"
      },
      "source": [
        "Let's try running an insanely large module: switch-base-128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ssny-jxuZyKF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "807d2a99-1313-48f4-d651-c1c257f6b6ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-12-29 16:08:34.851022: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-29 16:08:34.871469: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-29 16:08:34.877651: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "Directory /content/drive/MyDrive/MLSys_Learning/SiDA-MoE/data/sst2/switch-base-128/ already exists\n",
            "Loading checkpoint shards: 100% 3/3 [09:46<00:00, 195.60s/it]\n",
            "======================================================================================\n",
            "13.807333 GB\n",
            "[0]: 0.026374 GB\n",
            "[1]: 2.259161 GB\n",
            "[2]: 0.026373 GB\n",
            "[3]: 2.259161 GB\n",
            "[4]: 0.026373 GB\n",
            "[5]: 2.259161 GB\n",
            "[6]: 0.026373 GB\n",
            "[7]: 2.259161 GB\n",
            "[8]: 0.026373 GB\n",
            "[9]: 2.259161 GB\n",
            "[10]: 0.026373 GB\n",
            "[11]: 2.259161 GB\n",
            "[Experts]  13.55496597290039\n",
            "27it [00:20,  1.31it/s]\n",
            "Average GPU Utilization over time during inference: 65.39%\n"
          ]
        }
      ],
      "source": [
        "!python3 main.py --model=switch-base-128\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xxAr9-yu3Ys"
      },
      "outputs": [],
      "source": [
        "#!python3 main.py --model=switch-base-128 --sharding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBP7HQ4fvGlo"
      },
      "outputs": [],
      "source": [
        "# c4_en is way too large, for multirc, CUDA out-of-memory\n",
        "#!python3 main.py --dataset=multirc --model=switch-base-128"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKqlPJCzAyao"
      },
      "source": [
        "Try switch-base-256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4EinBhzoA0lH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1389d8ba-eaea-4b1e-8228-0219c4ac1fa6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-12-29 17:27:52.280870: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-29 17:27:52.302471: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-29 17:27:52.309050: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "Directory /content/drive/MyDrive/MLSys_Learning/SiDA-MoE/data/sst2/switch-base-256/ already exists\n",
            "Loading checkpoint shards: 100% 6/6 [02:16<00:00, 22.80s/it]\n",
            "======================================================================================\n",
            "27.309530 GB\n",
            "[0]: 0.026374 GB\n",
            "[1]: 4.509527 GB\n",
            "[2]: 0.026373 GB\n",
            "[3]: 4.509527 GB\n",
            "[4]: 0.026373 GB\n",
            "[5]: 4.509527 GB\n",
            "[6]: 0.026373 GB\n",
            "[7]: 4.509527 GB\n",
            "[8]: 0.026373 GB\n",
            "[9]: 4.509527 GB\n",
            "[10]: 0.026373 GB\n",
            "[11]: 4.509527 GB\n",
            "[Experts]  27.05716323852539\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/MLSys_Learning/SiDA-MoE/src/main.py\", line 135, in <module>\n",
            "    main()\n",
            "  File \"/content/drive/MyDrive/MLSys_Learning/SiDA-MoE/src/main.py\", line 102, in main\n",
            "    model.to(\"cuda\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\", line 3164, in to\n",
            "    return super().to(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n",
            "    return self._apply(convert)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n",
            "    module._apply(fn)\n",
            "  [Previous line repeated 7 more times]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n",
            "    param_applied = fn(param)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n",
            "    return t.to(\n",
            "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 22.17 GiB of which 6.88 MiB is free. Process 372653 has 22.15 GiB memory in use. Of the allocated memory 19.78 GiB is allocated by PyTorch, and 2.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        }
      ],
      "source": [
        "torch.cuda.empty_cache()\n",
        "!python3 main.py --model=switch-base-256"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyMESPIhRmgdmwedwMovvZgZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}